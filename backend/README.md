# Cab Compare Backend ğŸš•

Real-time price comparison backend for Ola, Uber, Rapido, and Namma Yatri.

## ğŸ¯ What This Does

This backend service:
- Scrapes real-time prices from 4 cab services
- Runs all scrapers in parallel (fast!)
- Manages user sessions/cookies
- Provides REST API for mobile app
- Generates deep links for booking

## ğŸ“¦ Prerequisites

- **Node.js** (v16 or higher)
- **npm** or **yarn**
- 2GB RAM minimum
- Linux/Mac/Windows

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
cd backend
npm install
```

### 2. Setup Environment

```bash
# Copy example env file
cp .env.example .env

# Edit .env with your settings (optional for testing)
nano .env
```

### 3. Run the Server

```bash
# Development mode (with auto-reload)
npm run dev

# Production mode
npm start
```

Server will start on `http://localhost:3000`

## ğŸ“¡ API Endpoints

### 1. Health Check
```bash
GET /health
```
**Response:**
```json
{
  "status": "ok",
  "message": "Cab Compare Backend is running",
  "timestamp": "2025-01-07T15:30:00.000Z"
}
```

### 2. Compare Prices
```bash
POST /api/prices/compare
Content-Type: application/json

{
  "pickup": "Sivaprakasam Nagar, Chennai",
  "drop": "Anna Nagar, Chennai",
  "sessions": {
    "ola": { "cookies": [...] },
    "uber": { "cookies": [...] },
    "rapido": { "cookies": [...] },
    "nammayatri": { "cookies": [...] }
  }
}
```

**Response:**
```json
{
  "success": true,
  "route": {
    "pickup": "Sivaprakasam Nagar, Chennai",
    "drop": "Anna Nagar, Chennai"
  },
  "prices": [
    {
      "service": "Ola",
      "success": true,
      "price": 120,
      "currency": "INR",
      "rideType": "Auto",
      "eta": "5 mins"
    },
    {
      "service": "Uber",
      "success": true,
      "price": 135,
      "currency": "INR",
      "rideType": "UberGo",
      "eta": "4 mins"
    },
    {
      "service": "Rapido",
      "success": true,
      "price": 95,
      "currency": "INR",
      "rideType": "Bike",
      "eta": "3 mins"
    },
    {
      "service": "Namma Yatri",
      "success": true,
      "price": 110,
      "currency": "INR",
      "rideType": "Auto",
      "eta": "6 mins"
    }
  ],
  "cheapest": {
    "service": "Rapido",
    "price": 95,
    "currency": "INR",
    "rideType": "Bike"
  },
  "stats": {
    "totalServices": 4,
    "successfulServices": 4,
    "failedServices": 0,
    "duration": "4.32s",
    "minPrice": 95,
    "maxPrice": 135,
    "avgPrice": "115",
    "priceDifference": 40,
    "savings": 40
  },
  "deepLinks": {
    "ola": "https://book.olacabs.com/?pickup=...",
    "uber": "uber://?action=setPickup&...",
    "rapido": "https://www.rapido.bike/ride?...",
    "nammayatri": "nammayatri://ride?..."
  },
  "timestamp": "2025-01-07T15:30:00.000Z"
}
```

### 3. Save User Session
```bash
POST /api/auth/save-session
Content-Type: application/json

{
  "userId": "user123",
  "service": "ola",
  "cookies": [
    {
      "name": "session_id",
      "value": "abc123...",
      "domain": ".olacabs.com"
    }
  ]
}
```

### 4. Get User Sessions
```bash
GET /api/auth/get-sessions/user123
```

### 5. Get Deep Links
```bash
GET /api/prices/deep-links?pickup=Location1&drop=Location2
```

## ğŸ”§ Configuration

### Environment Variables

```env
# Server
PORT=3000
NODE_ENV=development

# Sessions
SESSION_SECRET=your-secret-key

# CORS
ALLOWED_ORIGINS=http://localhost:3000

# Scraping
SCRAPING_TIMEOUT=30000
MAX_CONCURRENT_SCRAPES=4
```

## ğŸ—ï¸ Project Structure

```
backend/
â”œâ”€â”€ server.js              # Main Express server
â”œâ”€â”€ package.json           # Dependencies
â”œâ”€â”€ .env                   # Environment variables
â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ prices.js         # Price comparison endpoints
â”‚   â””â”€â”€ auth.js           # Session management endpoints
â”œâ”€â”€ scrapers/
â”‚   â”œâ”€â”€ index.js          # Main comparison orchestrator
â”‚   â”œâ”€â”€ ola.js            # Ola scraper
â”‚   â”œâ”€â”€ uber.js           # Uber scraper
â”‚   â”œâ”€â”€ rapido.js         # Rapido scraper
â”‚   â””â”€â”€ nammayatri.js     # Namma Yatri scraper
â””â”€â”€ data/
    â””â”€â”€ sessions.json     # User sessions (file-based storage)
```

## ğŸ› Testing

### Test Health Endpoint
```bash
curl http://localhost:3000/health
```

### Test Price Comparison (without sessions)
```bash
curl -X POST http://localhost:3000/api/prices/compare \
  -H "Content-Type: application/json" \
  -d '{
    "pickup": "Sivaprakasam Nagar, Chennai",
    "drop": "Anna Nagar, Chennai"
  }'
```

**Note:** Without valid sessions, scrapers may fail at login stage.

## ğŸ“± Mobile App Integration

The mobile app should:

1. **First Time Setup:**
   - User opens each service in WebView
   - User logs in
   - App captures cookies/tokens
   - App sends to backend via `/api/auth/save-session`

2. **Every Comparison:**
   - User enters pickup/drop
   - App calls `/api/prices/compare` with user sessions
   - App displays results
   - User clicks "Book with X" using deep links

## ğŸš€ Deployment

### Option 1: Railway.app (Easiest)
```bash
# Install Railway CLI
npm i -g @railway/cli

# Login
railway login

# Deploy
railway up
```
**Cost:** Free tier available, then ~â‚¹2000/month

### Option 2: DigitalOcean
1. Create a Droplet (Ubuntu 22.04)
2. Install Node.js
3. Clone your code
4. Run with PM2:
```bash
npm install -g pm2
pm2 start server.js --name cab-compare
pm2 save
```
**Cost:** â‚¹500-2000/month depending on size

### Option 3: Render.com
1. Connect GitHub repo
2. Set build command: `npm install`
3. Set start command: `npm start`
4. Deploy

**Cost:** Free tier available

## âš ï¸ Important Notes

### 1. Legal Considerations
- Web scraping may violate terms of service
- This is for educational purposes
- Consider reaching out to services for official API access
- Use responsibly

### 2. Session Management
- Current implementation uses file storage
- For production, use Redis or database
- Implement proper encryption for cookies
- Add session expiry logic

### 3. Rate Limiting
- Services may block excessive requests
- Implement caching (5-10 min)
- Add request delays between scrapes
- Monitor for IP blocks

### 4. Error Handling
- Scrapers may fail due to website changes
- Always have fallback mechanisms
- Log errors for debugging
- Update selectors as needed

## ğŸ”’ Security

### Before Production:
1. âœ… Change SESSION_SECRET in .env
2. âœ… Enable HTTPS
3. âœ… Implement rate limiting
4. âœ… Add authentication for API
5. âœ… Encrypt stored sessions
6. âœ… Use environment variables for secrets
7. âœ… Set up monitoring/logging

## ğŸ“Š Monitoring

### Recommended Tools:
- **Sentry**: Error tracking
- **PM2**: Process management
- **Logs**: Use Winston or Pino
- **Uptime**: UptimeRobot (free)

## ğŸ¤ Contributing

This is your project! Improve it as needed:
- Add caching layer
- Improve scraper selectors
- Add more error handling
- Optimize performance

## ğŸ“ Support

For issues:
1. Check logs: `pm2 logs cab-compare`
2. Verify network access to cab sites
3. Update Puppeteer if sites change
4. Check session validity

## ğŸ“ License

MIT License - Use freely for your startup!

---

Built with â¤ï¸ for comparing cab prices in India ğŸ‡®ğŸ‡³
